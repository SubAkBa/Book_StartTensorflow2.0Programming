{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7.2.3 - GRU 레이어",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxNpCHsfltTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e1163c8a-ff02-42af-8d48-900bfce50f0b"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for i in range(3000):\n",
        "  # 0 ~ 1 범위의 랜덤한 숫자 100개를 만듭니다.\n",
        "  lst = np.random.rand(100)\n",
        "\n",
        "  # 마킹할 숫자 2개의 인덱스를 뽑습니다.\n",
        "  idx = np.random.choice(100, 2, replace = False)\n",
        "  \n",
        "  # 마킹 인덱스가 저장된 원-핫 인코딩 벡터를 만듭니다.\n",
        "  zeros = np.zeros(100)\n",
        "  zeros[idx] = 1\n",
        "\n",
        "  # 마킹 인덱스와 랜덤한 숫자를 합쳐서 X에 저장합니다.\n",
        "  X.append(np.array(list(zip(zeros, lst))))\n",
        "\n",
        "  # 마킹 인덱스가 1인 값만 서로 곱해서 Y에 저장합니다.\n",
        "  Y.append(np.prod(lst[idx]))\n",
        "\n",
        "print(X[0], Y[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.12227751]\n",
            " [0.         0.66349993]\n",
            " [0.         0.10600637]\n",
            " [0.         0.78791792]\n",
            " [0.         0.18395198]\n",
            " [0.         0.49826885]\n",
            " [0.         0.25742512]\n",
            " [0.         0.5238619 ]\n",
            " [0.         0.26528095]\n",
            " [0.         0.32222993]\n",
            " [0.         0.33515402]\n",
            " [0.         0.5527128 ]\n",
            " [0.         0.44097548]\n",
            " [0.         0.98048851]\n",
            " [0.         0.20632807]\n",
            " [0.         0.92379715]\n",
            " [0.         0.25146336]\n",
            " [0.         0.1309099 ]\n",
            " [0.         0.95153313]\n",
            " [0.         0.72081145]\n",
            " [0.         0.458978  ]\n",
            " [0.         0.95338906]\n",
            " [0.         0.67884412]\n",
            " [0.         0.11381797]\n",
            " [0.         0.8481048 ]\n",
            " [0.         0.83909693]\n",
            " [0.         0.58241225]\n",
            " [0.         0.88913481]\n",
            " [0.         0.41816518]\n",
            " [0.         0.88431063]\n",
            " [0.         0.3253161 ]\n",
            " [0.         0.27980305]\n",
            " [0.         0.47565211]\n",
            " [0.         0.26375358]\n",
            " [0.         0.1955239 ]\n",
            " [0.         0.11118975]\n",
            " [0.         0.01037343]\n",
            " [0.         0.58274887]\n",
            " [0.         0.99534044]\n",
            " [0.         0.42902746]\n",
            " [0.         0.04403114]\n",
            " [0.         0.08568898]\n",
            " [0.         0.20283589]\n",
            " [0.         0.92223511]\n",
            " [0.         0.82592843]\n",
            " [0.         0.91904932]\n",
            " [0.         0.0216218 ]\n",
            " [1.         0.18347796]\n",
            " [0.         0.03312895]\n",
            " [0.         0.48129753]\n",
            " [0.         0.87214977]\n",
            " [0.         0.29434753]\n",
            " [0.         0.39831878]\n",
            " [0.         0.74521636]\n",
            " [0.         0.97390373]\n",
            " [0.         0.81638257]\n",
            " [0.         0.23001687]\n",
            " [0.         0.5662703 ]\n",
            " [0.         0.5950044 ]\n",
            " [0.         0.29949055]\n",
            " [0.         0.69146526]\n",
            " [0.         0.12865307]\n",
            " [0.         0.28728904]\n",
            " [0.         0.59607391]\n",
            " [0.         0.10318086]\n",
            " [0.         0.84015038]\n",
            " [0.         0.04270885]\n",
            " [0.         0.41804768]\n",
            " [0.         0.36014864]\n",
            " [0.         0.82230705]\n",
            " [0.         0.12566241]\n",
            " [0.         0.22802694]\n",
            " [0.         0.94272815]\n",
            " [0.         0.11884836]\n",
            " [0.         0.32763428]\n",
            " [0.         0.69208643]\n",
            " [0.         0.34526957]\n",
            " [0.         0.69311481]\n",
            " [1.         0.04381161]\n",
            " [0.         0.02623208]\n",
            " [0.         0.79716154]\n",
            " [0.         0.80780895]\n",
            " [0.         0.6382715 ]\n",
            " [0.         0.20968373]\n",
            " [0.         0.0548757 ]\n",
            " [0.         0.25601281]\n",
            " [0.         0.88295856]\n",
            " [0.         0.77234863]\n",
            " [0.         0.90303118]\n",
            " [0.         0.27572372]\n",
            " [0.         0.17009065]\n",
            " [0.         0.5595825 ]\n",
            " [0.         0.18505281]\n",
            " [0.         0.26967725]\n",
            " [0.         0.06045479]\n",
            " [0.         0.6429497 ]\n",
            " [0.         0.4978336 ]\n",
            " [0.         0.8278887 ]\n",
            " [0.         0.84108464]\n",
            " [0.         0.47884533]] 0.008038464202873255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R29braJi69H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "9447fc43-8b3d-455f-a77f-8c4190fee66e"
      },
      "source": [
        "# 예제 7.15 : GRU 레이어를 이용한 곱셈 문제 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.GRU(units = 30, return_sequences = True, input_shape = [100, 2]),\n",
        "                             tf.keras.layers.GRU(units = 30),\n",
        "                             tf.keras.layers.Dense(units = 1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'mse')\n",
        "model.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru (GRU)                    (None, 100, 30)           3060      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 30)                5580      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 8,671\n",
            "Trainable params: 8,671\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psR1_2T-lLhf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82dd3c36-ec7f-4742-fddc-b1b5884e47e4"
      },
      "source": [
        "# 예제 7.16 : GRU 네트워크 학습\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "history = model.fit(X[: 2560], Y[: 2560], epochs = 100, validation_split = 0.2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "64/64 [==============================] - 1s 20ms/step - loss: 0.0531 - val_loss: 0.0565\n",
            "Epoch 2/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0510 - val_loss: 0.0563\n",
            "Epoch 3/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0507 - val_loss: 0.0577\n",
            "Epoch 4/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0512 - val_loss: 0.0567\n",
            "Epoch 5/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0505 - val_loss: 0.0562\n",
            "Epoch 6/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0508 - val_loss: 0.0561\n",
            "Epoch 7/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0506 - val_loss: 0.0573\n",
            "Epoch 8/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0509 - val_loss: 0.0560\n",
            "Epoch 9/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0508 - val_loss: 0.0560\n",
            "Epoch 10/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0507 - val_loss: 0.0561\n",
            "Epoch 11/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0503 - val_loss: 0.0572\n",
            "Epoch 12/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0507 - val_loss: 0.0559\n",
            "Epoch 13/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0502 - val_loss: 0.0559\n",
            "Epoch 14/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0504 - val_loss: 0.0558\n",
            "Epoch 15/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0497 - val_loss: 0.0555\n",
            "Epoch 16/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0494 - val_loss: 0.0550\n",
            "Epoch 17/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0490 - val_loss: 0.0536\n",
            "Epoch 18/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0476 - val_loss: 0.0483\n",
            "Epoch 19/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0227 - val_loss: 0.0036\n",
            "Epoch 20/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0030 - val_loss: 0.0021\n",
            "Epoch 21/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 22/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 23/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 24/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 25/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 26/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 27/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 9.0462e-04 - val_loss: 0.0011\n",
            "Epoch 28/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 8.3589e-04 - val_loss: 8.7079e-04\n",
            "Epoch 29/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 8.1166e-04 - val_loss: 9.2638e-04\n",
            "Epoch 30/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 7.0834e-04 - val_loss: 9.3110e-04\n",
            "Epoch 31/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 6.8726e-04 - val_loss: 7.9020e-04\n",
            "Epoch 32/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 6.5227e-04 - val_loss: 7.4113e-04\n",
            "Epoch 33/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 7.1835e-04 - val_loss: 0.0012\n",
            "Epoch 34/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 6.9083e-04 - val_loss: 6.5103e-04\n",
            "Epoch 35/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 6.9514e-04 - val_loss: 6.5913e-04\n",
            "Epoch 36/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 5.2680e-04 - val_loss: 6.0919e-04\n",
            "Epoch 37/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 6.0314e-04 - val_loss: 6.5313e-04\n",
            "Epoch 38/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 5.1966e-04 - val_loss: 5.9976e-04\n",
            "Epoch 39/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 6.1358e-04 - val_loss: 7.9034e-04\n",
            "Epoch 40/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 5.0796e-04 - val_loss: 5.2312e-04\n",
            "Epoch 41/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 4.4394e-04 - val_loss: 6.3490e-04\n",
            "Epoch 42/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 4.9910e-04 - val_loss: 6.2094e-04\n",
            "Epoch 43/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 4.3133e-04 - val_loss: 4.7397e-04\n",
            "Epoch 44/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 3.8974e-04 - val_loss: 4.7336e-04\n",
            "Epoch 45/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 4.0051e-04 - val_loss: 4.8372e-04\n",
            "Epoch 46/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 3.9814e-04 - val_loss: 5.0519e-04\n",
            "Epoch 47/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 5.3416e-04 - val_loss: 6.8048e-04\n",
            "Epoch 48/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 4.3520e-04 - val_loss: 4.7078e-04\n",
            "Epoch 49/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 3.7632e-04 - val_loss: 5.2400e-04\n",
            "Epoch 50/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 3.4782e-04 - val_loss: 4.0595e-04\n",
            "Epoch 51/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 3.5331e-04 - val_loss: 4.0338e-04\n",
            "Epoch 52/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 3.6031e-04 - val_loss: 5.2017e-04\n",
            "Epoch 53/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 3.5637e-04 - val_loss: 6.5972e-04\n",
            "Epoch 54/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 3.5588e-04 - val_loss: 5.8205e-04\n",
            "Epoch 55/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 3.6861e-04 - val_loss: 3.8179e-04\n",
            "Epoch 56/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 3.1238e-04 - val_loss: 4.2201e-04\n",
            "Epoch 57/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 3.2500e-04 - val_loss: 4.1810e-04\n",
            "Epoch 58/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 3.2599e-04 - val_loss: 3.9408e-04\n",
            "Epoch 59/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 3.5964e-04 - val_loss: 4.6996e-04\n",
            "Epoch 60/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.9170e-04 - val_loss: 4.1956e-04\n",
            "Epoch 61/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 2.8095e-04 - val_loss: 3.3383e-04\n",
            "Epoch 62/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.6896e-04 - val_loss: 5.6389e-04\n",
            "Epoch 63/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 2.9127e-04 - val_loss: 3.1267e-04\n",
            "Epoch 64/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.5821e-04 - val_loss: 3.0479e-04\n",
            "Epoch 65/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.5775e-04 - val_loss: 2.8671e-04\n",
            "Epoch 66/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.7071e-04 - val_loss: 3.9397e-04\n",
            "Epoch 67/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.6100e-04 - val_loss: 3.5238e-04\n",
            "Epoch 68/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.4652e-04 - val_loss: 3.5322e-04\n",
            "Epoch 69/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 3.0053e-04 - val_loss: 3.4981e-04\n",
            "Epoch 70/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 4.3667e-04 - val_loss: 4.9443e-04\n",
            "Epoch 71/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.7070e-04 - val_loss: 2.6690e-04\n",
            "Epoch 72/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 3.5103e-04 - val_loss: 4.3382e-04\n",
            "Epoch 73/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.2753e-04 - val_loss: 2.9169e-04\n",
            "Epoch 74/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.1649e-04 - val_loss: 3.4039e-04\n",
            "Epoch 75/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 2.0499e-04 - val_loss: 2.4834e-04\n",
            "Epoch 76/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.6594e-04 - val_loss: 3.2666e-04\n",
            "Epoch 77/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.0142e-04 - val_loss: 2.7289e-04\n",
            "Epoch 78/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.4269e-04 - val_loss: 2.6803e-04\n",
            "Epoch 79/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 2.4216e-04 - val_loss: 2.8827e-04\n",
            "Epoch 80/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.0636e-04 - val_loss: 2.2100e-04\n",
            "Epoch 81/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.1824e-04 - val_loss: 2.3202e-04\n",
            "Epoch 82/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 1.8907e-04 - val_loss: 2.1936e-04\n",
            "Epoch 83/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 1.7570e-04 - val_loss: 3.0563e-04\n",
            "Epoch 84/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.2482e-04 - val_loss: 2.0146e-04\n",
            "Epoch 85/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 1.8752e-04 - val_loss: 2.3593e-04\n",
            "Epoch 86/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.0724e-04 - val_loss: 2.0321e-04\n",
            "Epoch 87/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 1.6296e-04 - val_loss: 2.5614e-04\n",
            "Epoch 88/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.6935e-04 - val_loss: 2.3957e-04\n",
            "Epoch 89/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 4.0861e-04 - val_loss: 4.9875e-04\n",
            "Epoch 90/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 2.1384e-04 - val_loss: 2.9823e-04\n",
            "Epoch 91/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 2.2616e-04 - val_loss: 2.8357e-04\n",
            "Epoch 92/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 1.6690e-04 - val_loss: 2.4462e-04\n",
            "Epoch 93/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 2.0089e-04 - val_loss: 2.5411e-04\n",
            "Epoch 94/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 1.7811e-04 - val_loss: 1.7336e-04\n",
            "Epoch 95/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 1.4237e-04 - val_loss: 2.0106e-04\n",
            "Epoch 96/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 1.4872e-04 - val_loss: 1.7538e-04\n",
            "Epoch 97/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 1.8513e-04 - val_loss: 2.2264e-04\n",
            "Epoch 98/100\n",
            "64/64 [==============================] - 1s 11ms/step - loss: 1.5237e-04 - val_loss: 2.5044e-04\n",
            "Epoch 99/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 1.4055e-04 - val_loss: 1.8074e-04\n",
            "Epoch 100/100\n",
            "64/64 [==============================] - 1s 12ms/step - loss: 1.5823e-04 - val_loss: 2.2683e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3ZDa6ZHl0yz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "42ca9ad1-0ad6-4918-864a-2869992e4acb"
      },
      "source": [
        "# 예제 7.17 : GRU 네트워크의 학습 결과 확인\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], 'b-', label = 'loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTV8xY2WmLr-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c40dc4fb-df81-4f0f-9891-7a160ce090ba"
      },
      "source": [
        "# 예제 7.18 : 테스트 데이터에 대한 예측 정확도 확인\n",
        "model.evaluate(X[2560 :], Y[2560 :])\n",
        "prediction = model.predict(X[2560 : 2560 + 5])\n",
        "\n",
        "for i in range(5):\n",
        "  print(Y[2560 + i], '\\t', prediction[i][0], '\\tdiff', abs(prediction[i][0] - Y[2560 + i]))\n",
        "\n",
        "prediction = model.predict(X[2560 :])\n",
        "cnt = 0\n",
        "\n",
        "for i in range(len(prediction)):\n",
        "  if abs(prediction[i][0] - Y[2560 + i]) > 0.04:\n",
        "    cnt += 1\n",
        "\n",
        "print('correctness:', (440 - cnt) / 440 * 100, '%')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 5ms/step - loss: 2.6152e-04\n",
            "0.20773870194822278 \t 0.20420301 \tdiff 0.003535692342815061\n",
            "0.30296292219475635 \t 0.2918877 \tdiff 0.011075221637047605\n",
            "0.12229749991381507 \t 0.13077615 \tdiff 0.008478652100917292\n",
            "0.5890254019001319 \t 0.61266583 \tdiff 0.02364043014256223\n",
            "0.008435697759728324 \t 0.008502409 \tdiff 6.67111023856283e-05\n",
            "correctness: 97.95454545454545 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}